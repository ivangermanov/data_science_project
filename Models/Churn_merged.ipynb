{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "\n",
    "# Plotly requirements\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "# Machine learning models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import model_selection\n",
    "from IPython.display import display\n",
    "\n",
    "# Additions\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_path = '../orders_churn.csv'\n",
    "\n",
    "df = pd.read_csv(orders_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_performance(name, y_pred, y_score): \n",
    "    mycolors = [[0.0, 'rgb(165,0,38)'],\n",
    "                  [0.1111111111111111, 'rgb(215,48,39)'],\n",
    "                  [0.2222222222222222, 'rgb(244,109,67)'],\n",
    "                  [0.3333333333333333, 'rgb(253,174,97)'],\n",
    "                  [0.4444444444444444, 'rgb(254,224,144)'],\n",
    "                  [0.5555555555555556, 'rgb(224,243,248)'],\n",
    "                  [0.6666666666666666, 'rgb(171,217,233)'],\n",
    "                  [0.7777777777777778, 'rgb(116,173,209)'],\n",
    "                  [0.8888888888888888, 'rgb(69,117,180)'],\n",
    "                  [1.0, 'rgb(49,54,149)']]\n",
    "    \n",
    "    #plot confusion matrix\n",
    "    conf_matrix = confusion_matrix(target_test, y_pred)\n",
    "    trace1 = go.Heatmap(z = conf_matrix  ,x = [\"0 (pred)\",\"1 (pred)\"],\n",
    "                        y = [\"0 (true)\",\"1 (true)\"],xgap = 2, ygap = 2, \n",
    "                        colorscale = mycolors, showscale  = False)\n",
    "\n",
    "    #get metrics\n",
    "    tp = conf_matrix[1,1]\n",
    "    fn = conf_matrix[1,0]\n",
    "    fp = conf_matrix[0,1]\n",
    "    tn = conf_matrix[0,0]\n",
    "    Accuracy  =  ((tp+tn)/(tp+tn+fp+fn))\n",
    "    Precision =  (tp/(tp+fp))\n",
    "    Recall    =  (tp/(tp+fn))\n",
    "    F1_score  =  (2*(((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))))\n",
    "\n",
    "    show_metrics = pd.DataFrame(data=[[Accuracy , Precision, Recall, F1_score]])\n",
    "    show_metrics = show_metrics.T\n",
    "\n",
    "    #plot metrix barPlot\n",
    "    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue']\n",
    "    trace2 = go.Bar(x = (show_metrics[0].values), \n",
    "                   y = ['Accuracy', 'Precision', 'Recall', 'F1_score'], text = np.round_(show_metrics[0].values,4),\n",
    "                    textposition = 'auto',\n",
    "                   orientation = 'h', opacity = 0.8,marker=dict(\n",
    "            color=colors,\n",
    "            line=dict(color='#000000',width=1.5)))\n",
    "    \n",
    "    #plot ROC-curve\n",
    "    model_roc_auc = round(roc_auc_score(target_test, y_score) , 3)\n",
    "    fpr, tpr, t = roc_curve(target_test, y_score)\n",
    "    trace3 = go.Scatter(x = fpr,y = tpr,\n",
    "                        name = \"Roc : \",\n",
    "                        line = dict(color = ('lightskyblue'),width = 2), fill='tozeroy')\n",
    "    trace4 = go.Scatter(x = [0,1],y = [0,1],\n",
    "                        line = dict(color = ('black'),width = 1.5,\n",
    "                        dash = 'dot'))\n",
    "    \n",
    "    #plot Precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(target_test, y_score)\n",
    "    trace5 = go.Scatter(x = recall, y = precision,\n",
    "                        name = \"Precision\" + str(precision),\n",
    "                        line = dict(color = ('gold'),width = 2), fill='tozeroy')\n",
    "    \n",
    "    #subplots\n",
    "    fig = tls.make_subplots(rows=2, cols=2, print_grid=False, \n",
    "                        subplot_titles=('Confusion Matrix',\n",
    "                                        'Metrics',\n",
    "                                        'ROC curve'+\" \"+ '('+ str(model_roc_auc)+')',\n",
    "                                        'Precision - Recall curve'))\n",
    "    \n",
    "    fig.append_trace(trace1,1,1)\n",
    "    fig.append_trace(trace2,1,2)\n",
    "    fig.append_trace(trace3,2,1)\n",
    "    fig.append_trace(trace4,2,1)\n",
    "    fig.append_trace(trace5,2,2)\n",
    "    \n",
    "    fig['layout'].update(showlegend = False, title = '<b>Model performance</b><br>'+name,\n",
    "                        autosize = False, height = 900,width = 830,\n",
    "                        plot_bgcolor = 'rgba(240,240,240, 0.95)',\n",
    "                        paper_bgcolor = 'rgba(240,240,240, 0.95)',\n",
    "                        margin = dict(b = 195))\n",
    "    fig[\"layout\"][\"xaxis2\"].update((dict(range=[0, 1])))\n",
    "    fig[\"layout\"][\"xaxis3\"].update(dict(title = \"false positive rate\"))\n",
    "    fig[\"layout\"][\"yaxis3\"].update(dict(title = \"true positive rate\"))\n",
    "    fig[\"layout\"][\"xaxis4\"].update(dict(title = \"recall\"), range = [0,1.05])\n",
    "    fig[\"layout\"][\"yaxis4\"].update(dict(title = \"precision\"), range = [0,1.05])\n",
    "    fig.layout.titlefont.size = 14\n",
    "    \n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model):\n",
    "    tmp = pd.DataFrame({'Feature': list(df), 'Feature importance': model.feature_importances_})\n",
    "    tmp = tmp.sort_values(by='Feature importance',ascending=False).head(30)\n",
    "    plt.figure(figsize = (10,12))\n",
    "    plt.title('Top 30 - Features importance',fontsize=14)\n",
    "    s = sns.barplot(y='Feature',x='Feature importance',data=tmp, orient='h')\n",
    "    s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Def X and Y\n",
    "y = np.array(df.Churn.tolist())\n",
    "df = df.drop('Churn', 1)\n",
    "X = np.array(df.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets as well as for validation and testing\n",
    "train, test, target_train, target_test = train_test_split(X, y, train_size= 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since there is a severe imbalance in the values within the target variable, \n",
    "#I will use the SMOTE method in the dealing with this skewed value via the imblearn Python package.\n",
    "\n",
    "oversampler = SMOTE(random_state=0)\n",
    "smote_train, smote_target_train = oversampler.fit_sample(train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "#models.append(('KNN', KNeighborsClassifier(n_neighbors=5)))\n",
    "#models.append(('Random Forest', RandomForestClassifier(50, criterion='entropy')))\n",
    "models.append(('XGBClassifier', xgb.XGBClassifier(max_depth=3, learning_rate=0.1,\n",
    "                                                  n_estimators=300, booster='gbtree', n_jobs=1)))\n",
    "\n",
    "for name,model in models:\n",
    "    model.fit(smote_train, smote_target_train)\n",
    "    predictions = model.predict(test)\n",
    "    y_score = model.predict_proba(test)[:,1]\n",
    "    show_model_performance(name, predictions, y_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
